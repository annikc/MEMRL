{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1571cc9909b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mUtils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle \n",
    "import gym\n",
    "import sys\n",
    "import gym\n",
    "from Utils import softmax\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../../modules/')\n",
    "from Utils import running_mean as rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../Data/results/'\n",
    "df = pd.read_csv('../../Data/throttled_ec_training.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = {}\n",
    "envs = df.env_name.unique()\n",
    "reps = df.representation.unique()\n",
    "\n",
    "\n",
    "\n",
    "for env in envs:\n",
    "    master_dict[env] = {}\n",
    "    for rep in reps:\n",
    "        id_list = list(\n",
    "            df.loc[\n",
    "                (df['env_name']==env) \n",
    "              & (df['representation']==rep)\n",
    "            ]['save_id'])\n",
    "        master_dict[env][rep] = id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(master_dict)):\n",
    "    print('____________')\n",
    "    print(list(master_dict.keys())[i])\n",
    "    print(master_dict[envs[i]].keys())\n",
    "    for j in list(master_dict[envs[i]].keys()):\n",
    "        n = len(master_dict[envs[i]][j])\n",
    "        if n == 0:\n",
    "            master_dict[envs[i]].pop(j)\n",
    "        else:\n",
    "            print(f'{j} = {n} items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_std(list_of_ids, cutoff=5000):\n",
    "    results = []\n",
    "    for id_num in list_of_ids: \n",
    "        with open(data_dir+ f'{id_num}_data.p', 'rb') as f:\n",
    "            dats = pickle.load(f)\n",
    "            reward_info = dats['total_reward']\n",
    "            results.append(reward_info)\n",
    "            \n",
    "    pp = np.vstack(results)\n",
    "    \n",
    "    smoothing = 100\n",
    "    avg_ = rm(np.mean(pp,axis=0),smoothing)[0:cutoff]\n",
    "    std_ = rm(np.std(pp, axis=0), smoothing)[0:cutoff]\n",
    "    \n",
    "    return avg_, std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = 'gridworld:gridworld-v5'\n",
    "env = gym.make(environment)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "avdev_data = {}\n",
    "\n",
    "for key in master_dict[environment].keys():\n",
    "    v_list = master_dict[environment][key]\n",
    "    avg_, std_ = get_avg_std(v_list)\n",
    "    avdev_data[key] = [avg_, std_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare 3 types\n",
    "plt.figure()    \n",
    "for key in ['onehot', 'analytic successor', 'state-centred pc f0.05']:\n",
    "    avg_, std = avdev_data[key]\n",
    "    label= key\n",
    "    plt.plot(avg_, label=f'{label}')\n",
    "    plt.fill_between(np.arange(len(avg_)),avg_-std_, avg_+std_, alpha=0.3)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.15), ncol=4)\n",
    "plt.ylim([-4,12])\n",
    "plt.show()\n",
    "\n",
    "# compare 3 types of state-centred pc \n",
    "plt.figure()    \n",
    "for key in ['state-centred pc f0.05', 'state-centred pc f0.2', 'state-centred pc f0.1']:\n",
    "    avg_, std = avdev_data[key]\n",
    "    label= key[-7:]\n",
    "    plt.plot(avg_, label=f'{label}')\n",
    "    plt.fill_between(np.arange(len(avg_)),avg_-std_, avg_+std_, alpha=0.3)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.15), ncol=4)\n",
    "plt.show()\n",
    "\n",
    "# compare state-centred and random-centred plc\n",
    "plt.figure()    \n",
    "for key in ['state-centred pc f0.05', 'random-centred pc f_0.05']:\n",
    "    avg_, std = avdev_data[key]\n",
    "    label= key[-7:]\n",
    "    plt.plot(avg_, label=f'{label}')\n",
    "    plt.fill_between(np.arange(len(avg_)),avg_-std_, avg_+std_, alpha=0.3)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.15), ncol=4)\n",
    "plt.show()\n",
    "\n",
    "# compare analytic sr and td computed sr\n",
    "plt.figure()    \n",
    "for key in ['successor', 'analytic successor']:\n",
    "    avg_, std = avdev_data[key]\n",
    "    plt.plot(avg_, label=f'{key}')\n",
    "    plt.fill_between(np.arange(len(avg_)),avg_-std_, avg_+std_, alpha=0.3)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.15), ncol=4)\n",
    "plt.ylim([-4,12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = 'gridworld:gridworld-v2'\n",
    "env = gym.make(environment)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "avdev_data = {}\n",
    "\n",
    "for key in master_dict[environment].keys():\n",
    "    v_list = master_dict[environment][key]\n",
    "    avg_, std_ = get_avg_std(v_list)\n",
    "    avdev_data[key] = [avg_, std_]\n",
    "\n",
    "# compare 3 types\n",
    "plt.figure()    \n",
    "for key in ['analytic successor', 'state-centred pc f0.05']:\n",
    "    avg_, std = avdev_data[key]\n",
    "    label= key\n",
    "    plt.plot(avg_, label=f'{label}')\n",
    "    plt.fill_between(np.arange(len(avg_)),avg_-std_, avg_+std_, alpha=0.3)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.15), ncol=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = 'gridworld:gridworld-v3'\n",
    "env = gym.make(environment)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "avdev_data = {}\n",
    "\n",
    "for key in master_dict[environment].keys():\n",
    "    v_list = master_dict[environment][key]\n",
    "    avg_, std_ = get_avg_std(v_list)\n",
    "    avdev_data[key] = [avg_, std_]\n",
    "\n",
    "# compare 3 types\n",
    "plt.figure()    \n",
    "for key in ['analytic successor', 'state-centred pc f0.05']:\n",
    "    avg_, std = avdev_data[key]\n",
    "    label= key\n",
    "    plt.plot(avg_, label=f'{label}')\n",
    "    plt.fill_between(np.arange(len(avg_)),avg_-std_, avg_+std_, alpha=0.3)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.15), ncol=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = 'gridworld:gridworld-v4'\n",
    "env = gym.make(environment)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "avdev_data = {}\n",
    "\n",
    "for key in master_dict[environment].keys():\n",
    "    v_list = master_dict[environment][key]\n",
    "    avg_, std_ = get_avg_std(v_list)\n",
    "    avdev_data[key] = [avg_, std_]\n",
    "\n",
    "# compare 3 types\n",
    "plt.figure()    \n",
    "for key in ['analytic successor', 'state-centred pc f0.05']:\n",
    "    avg_, std = avdev_data[key]\n",
    "    label= key\n",
    "    plt.plot(avg_, label=f'{label}')\n",
    "    plt.fill_between(np.arange(len(avg_)),avg_-std_, avg_+std_, alpha=0.3)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.15), ncol=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_num = master_dict[envs[0]]['analytic successor'][0]\n",
    "\n",
    "with open(data_dir+ f'{id_num}_data.p', 'rb') as f:\n",
    "    dats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.gridworld_plotting import plot_pref_pol, plot_valmap, plot_polmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 4500\n",
    "policies = dats['P_snap'][index]\n",
    "values   = dats['V_snap'][index]\n",
    "plot_pref_pol(gym.make(envs[0]),policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_rwd = []\n",
    "for index in range(5000):\n",
    "    policies = dats['P_snap'][index]\n",
    "    reward_sum = 0 \n",
    "    for step in range(250):\n",
    "        action = np.random.choice(np.arange(4), 1, p=softmax(list(policies[env.oneD2twoD(env.state)])))[0]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "        if done:\n",
    "            break\n",
    "    tot_rwd.append(reward_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(tot_rwd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(list((0.2, 0.1, 0.1))) - np.asarray(list((0.1, 0.2,0.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
