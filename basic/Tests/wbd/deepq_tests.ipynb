{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../../../modules/')\n",
    "from Agents.RepresentationLearning import PlaceCells\n",
    "from Agents import DQ_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_state(state):\n",
    "    vec = np.zeros(env.nstates)\n",
    "    vec[state] = 1\n",
    "    return vec\n",
    "\n",
    "def onehot_state_collection(env):\n",
    "    collection = []\n",
    "    for state in range(env.nstates):\n",
    "        vec = one_hot_state(state)\n",
    "        collection.append(vec)\n",
    "    return collection\n",
    "\n",
    "def twoD_states(env):\n",
    "    twods = []\n",
    "    for state in range(env.nstates):\n",
    "        twod = env.oneD2twoD(state)\n",
    "        twods.append(twod)\n",
    "    return twods\n",
    "\n",
    "def plot_some_place_fields(env, list_of_coords, place_cells):\n",
    "    states = np.asarray(list_of_coords)\n",
    "    gridworld_pc_reps = place_cells.get_activities(list_of_coords)\n",
    "\n",
    "    num_pc_view = 9\n",
    "    get_rand_cells = np.random.choice(env.nstates,num_pc_view,replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(3,3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # for every state, get what the place cell activity is\n",
    "        ax.scatter(states[:,0],states[:,1], c =gridworld_pc_reps[:,get_rand_cells[i]])\n",
    "        cell_center = np.round(np.multiply(place_cells.cell_centres[get_rand_cells[i]],env.shape),1)\n",
    "        print(cell_center)\n",
    "        ax.set_title(f'{cell_center}')\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 176.4x176.4 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('gym_grid:gridworld-v111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get onehot activity vectors \n",
    "gridworld_onehots = onehot_state_collection(env)\n",
    "\n",
    "# get place cell activity vectors \n",
    "# make a collection of place cells\n",
    "place_cells       = PlaceCells(env.shape,env.nstates, field_size=1/env.shape[0])\n",
    "\n",
    "two_d_states = twoD_states(env) # get all states as coords\n",
    "# get activities for each state\n",
    "gridworld_pc_reps = place_cells.get_activities(two_d_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Reps for state 25:(3, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print onehot activity vector and place cell activity vector for a given state\n",
    "test_state = 25\n",
    "print(f'State Reps for state {test_state}:{two_d_states[test_state]}')\n",
    "fig, ax = plt.subplots(2,1,sharex=True)\n",
    "ax[0].imshow([gridworld_onehots[test_state]])\n",
    "ax[0].set_aspect('auto')\n",
    "ax[0].set_title('Onehot Rep')\n",
    "ax[1].imshow([gridworld_pc_reps[test_state]])\n",
    "ax[1].set_aspect('auto')\n",
    "ax[1].set_title('Place Cell Rep')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up agent parameters\n",
    "INPUT_DIMS = [env.nstates]\n",
    "N_ACTIONS  = env.action_space.n\n",
    "BATCH_SIZE = 64\n",
    "GAMMA      = 0.98\n",
    "EPSILON    = 1.0\n",
    "LR         = 0.01\n",
    "\n",
    "onehot_agent = DQ_agent(gamma=GAMMA, epsilon=EPSILON, lr=LR,\n",
    "                       input_dims=INPUT_DIMS, batch_size=BATCH_SIZE,\n",
    "                       n_actions=N_ACTIONS)\n",
    "placecell_agent = DQ_agent(gamma=GAMMA, epsilon=EPSILON, lr=LR,\n",
    "                       input_dims=INPUT_DIMS, batch_size=BATCH_SIZE,\n",
    "                       n_actions=N_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_expt(ntrials, nsteps, obs_container, agent):\n",
    "    scores, eps_history = [],[]\n",
    "    for trial in range(ntrials):\n",
    "        score = 0 \n",
    "        done  = False\n",
    "        state_id = env.reset()\n",
    "        observation = obs_container[state_id]\n",
    "        \n",
    "        for step in range(nsteps):\n",
    "            action = agent.choose_action([observation])\n",
    "            state_id, reward, done, info = env.step(action)\n",
    "            observation_ = obs_container[state_id]\n",
    "            score += reward\n",
    "            agent.store_transition(observation,action,reward,observation_,done)\n",
    "            agent.learn()\n",
    "            observation = observation_\n",
    "            if done:\n",
    "                break\n",
    "        scores.append(score)\n",
    "        eps_history.append(agent.epsilon)\n",
    "        \n",
    "        avg_score = np.mean(scores[-100:])\n",
    "        if trial%20==0:\n",
    "            print(f'episode:{trial}, score: {score}, avg:{ avg_score}, epsilon: {agent.epsilon}')\n",
    "    return scores, eps_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env1 = gym.make('LunarLander-v2')\n",
    "print(type(env1.reset()))\n",
    "print(type(gridworld_onehots[env.reset()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lunar_agent = DQ_agent(gamma=GAMMA, epsilon=EPSILON, lr=LR,\n",
    "                       input_dims=[8], batch_size=BATCH_SIZE,\n",
    "                       n_actions=N_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = torch.tensor([env1.reset()])\n",
    "testqvals = Lunar_agent.Q_eval(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = torch.Tensor([gridworld_onehots[env.reset()]])\n",
    "testqvals = onehot_agent.Q_eval(test_batch)\n",
    "print(testqvals)\n",
    "action = onehot_agent.choose_action(test_batch)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:0, score: -3.9999999999999587, avg:-3.9999999999999587, epsilon: 0.01\n",
      "episode:20, score: -3.9999999999999587, avg:-2.669047619047581, epsilon: 0.01\n",
      "episode:40, score: -3.9999999999999587, avg:-2.4302439024389875, epsilon: 0.01\n",
      "episode:60, score: -3.9999999999999587, avg:-2.716065573770455, epsilon: 0.01\n",
      "episode:80, score: -3.9999999999999587, avg:-2.5455555555555183, epsilon: 0.01\n",
      "episode:100, score: -3.9999999999999587, avg:-2.721499999999961, epsilon: 0.01\n",
      "episode:120, score: -3.9999999999999587, avg:-2.3901999999999632, epsilon: 0.01\n",
      "episode:140, score: -3.9999999999999587, avg:-2.474799999999963, epsilon: 0.01\n",
      "episode:160, score: -3.9999999999999587, avg:-2.3348999999999633, epsilon: 0.01\n",
      "episode:180, score: -3.9999999999999587, avg:-2.450199999999963, epsilon: 0.01\n",
      "episode:200, score: -3.9999999999999587, avg:-2.139599999999964, epsilon: 0.01\n",
      "episode:220, score: -3.9999999999999587, avg:-2.750399999999961, epsilon: 0.01\n",
      "episode:240, score: -3.9999999999999587, avg:-2.7498999999999616, epsilon: 0.01\n",
      "episode:260, score: -3.9999999999999587, avg:-3.029399999999961, epsilon: 0.01\n",
      "episode:280, score: -3.9999999999999587, avg:-3.30899999999996, epsilon: 0.01\n",
      "episode:300, score: -3.9999999999999587, avg:-3.719999999999958, epsilon: 0.01\n",
      "episode:320, score: -3.9999999999999587, avg:-3.719999999999958, epsilon: 0.01\n",
      "episode:340, score: -3.9999999999999587, avg:-3.9999999999999574, epsilon: 0.01\n",
      "episode:360, score: 9.96, avg:-3.592399999999959, epsilon: 0.01\n",
      "episode:380, score: -3.9999999999999587, avg:-2.815299999999961, epsilon: 0.01\n",
      "episode:400, score: -3.9999999999999587, avg:-2.4313999999999627, epsilon: 0.01\n",
      "episode:420, score: -3.9999999999999587, avg:-2.048399999999964, epsilon: 0.01\n",
      "episode:440, score: -3.9999999999999587, avg:-1.3496999999999664, epsilon: 0.01\n",
      "episode:460, score: -3.9999999999999587, avg:-0.6381999999999681, epsilon: 0.01\n",
      "episode:480, score: -3.9999999999999587, avg:-1.1704999999999666, epsilon: 0.01\n",
      "episode:500, score: -3.9999999999999587, avg:-1.0264999999999669, epsilon: 0.01\n",
      "episode:520, score: -3.9999999999999587, avg:-0.5256999999999679, epsilon: 0.01\n",
      "episode:540, score: -3.9999999999999587, avg:-0.9551999999999669, epsilon: 0.01\n",
      "episode:560, score: -3.9999999999999587, avg:-1.9434999999999645, epsilon: 0.01\n",
      "episode:580, score: -3.9999999999999587, avg:-2.0482999999999643, epsilon: 0.01\n",
      "episode:600, score: -3.9999999999999587, avg:-2.5761999999999627, epsilon: 0.01\n",
      "episode:620, score: -3.9999999999999587, avg:-3.459999999999959, epsilon: 0.01\n",
      "episode:640, score: -3.9999999999999587, avg:-3.729199999999958, epsilon: 0.01\n",
      "episode:660, score: -3.9999999999999587, avg:-3.859999999999958, epsilon: 0.01\n",
      "episode:680, score: -3.9999999999999587, avg:-3.9999999999999574, epsilon: 0.01\n",
      "episode:700, score: -3.9999999999999587, avg:-3.859999999999958, epsilon: 0.01\n",
      "episode:720, score: 9.99, avg:-3.720099999999958, epsilon: 0.01\n",
      "episode:740, score: -3.9999999999999587, avg:-2.799299999999961, epsilon: 0.01\n",
      "episode:760, score: -3.9999999999999587, avg:-2.5766999999999625, epsilon: 0.01\n",
      "episode:780, score: 6.640000000000027, avg:-2.224299999999964, epsilon: 0.01\n",
      "episode:800, score: -3.9999999999999587, avg:-2.2631999999999635, epsilon: 0.01\n",
      "episode:820, score: -3.9999999999999587, avg:-1.869299999999965, epsilon: 0.01\n",
      "episode:840, score: -3.9999999999999587, avg:-2.4149999999999627, epsilon: 0.01\n",
      "episode:860, score: -3.9999999999999587, avg:-2.2179999999999636, epsilon: 0.01\n",
      "episode:880, score: -3.9999999999999587, avg:-2.5703999999999625, epsilon: 0.01\n",
      "episode:900, score: -3.9999999999999587, avg:-2.5314999999999634, epsilon: 0.01\n",
      "episode:920, score: -3.9999999999999587, avg:-3.0652999999999606, epsilon: 0.01\n",
      "episode:940, score: -3.9999999999999587, avg:-3.4403999999999595, epsilon: 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-29af3d14a504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_expt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridworld_onehots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monehot_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-87ed37ad7144>\u001b[0m in \u001b[0;36mrun_expt\u001b[0;34m(ntrials, nsteps, obs_container, agent)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobservation_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservation_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/LINC Lab Documents/Code/MEMRL/basic/modules/Agents/Networks/DQN.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# backprop the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# weight update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;31m# now decrease epsilon value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_trials = 2000\n",
    "num_steps = 400\n",
    "scores, epsilons = run_expt(num_trials, num_steps, gridworld_onehots, onehot_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(scores, label='score')\n",
    "ax[1].plot(epsilons,label='epsilon')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
